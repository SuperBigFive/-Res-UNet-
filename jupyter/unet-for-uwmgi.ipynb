{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 📒 Notebooks\n","[UWMGI: Unet [Train] [PyTorch]](https://www.kaggle.com/code/awsaf49/uwmgi-unet-train-pytorch/)\n","<br/>\n","本人主要对该 $notebook$ 做了较详细的中文注释, 并根据个人需要适当修改、添加了部分代码(实验测试结果对比)。"]},{"cell_type":"markdown","metadata":{},"source":["# 🛠 Install Libraries\n","$Python$ 中以 $!$ 开头的代码是一种特殊的语法，称为 $shell$ 命令（$shell commands$）。$shell$ 命令可以在 $Python$ 代码中执行系统命令，比如 $ls$, $pwd$, $cd$ 等。$shell$ 命令通常用在 $Jupyter\\ Notebook$ 或 $IPython$ 等交互式环境中，以方便用户操作文件系统或其他外部程序。\n","\n","$-q$ 参数是用来指定 $pip$ 安装时的日志级别的，它表示 $quiet$ 模式，即安静模式。当使用 $-q$ 参数时，$pip$ 安装时只会输出错误和警告信息，不会输出正常的进度信息。这样可以减少输出的噪音，提高安装的效率。如果使用两个 $-q$ 参数，即 $-qq$，那么 $pip$ 安装时连错误和警告信息也不会输出，只有在发生异常时才会输出信息。\n","\n","$-qU$ 参数是用来指定 $pip$ 安装时的日志级别和升级模式的，它相当于 $-q$ $-U$ 的缩写。$-U$ 参数是用来指定 $pip$ 安装时是否升级已经安装的包的，它表示 $upgrade$ 模式，即升级模式。当使用 $-U$ 参数时，$pip$ 安装时会检查已经安装的包是否有更新的版本，如果有，则会自动升级到最新版本。这样可以保证安装的包是最新的，避免出现版本不兼容的问题。"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:09:59.060657Z","iopub.status.busy":"2023-10-15T14:09:59.059841Z","iopub.status.idle":"2023-10-15T14:10:38.581178Z","shell.execute_reply":"2023-10-15T14:10:38.580186Z","shell.execute_reply.started":"2023-10-15T14:09:59.060568Z"},"trusted":true},"outputs":[],"source":["!pip install -qq segmentation_models_pytorch\n","!pip install -qq -U wandb\n","!pip install -qq scikit-learn==1.0\n","!pip install -qq torchsummary"]},{"cell_type":"markdown","metadata":{},"source":["# 📚 Import Libraries \n","$Python$ 中 % 开头的代码的用法是一种特殊的语法，称为魔法命令（$magic\\ commands$）。魔法命令是一些可以在 $IPython$ 或 $Jupyter\\ Notebook$ 等交互式环境中执行的命令，它们可以提供一些方便的功能，比如控制输出格式、执行系统命令、加载扩展模块等"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:10:38.583662Z","iopub.status.busy":"2023-10-15T14:10:38.583403Z","iopub.status.idle":"2023-10-15T14:10:38.627156Z","shell.execute_reply":"2023-10-15T14:10:38.626463Z","shell.execute_reply.started":"2023-10-15T14:10:38.583630Z"},"trusted":true},"outputs":[],"source":["#导入 autoreload 扩展\n","%load_ext autoreload \n","# 导入的模块发生变化时，会自动重新加载\n","%autoreload 2 "]},{"cell_type":"code","execution_count":3,"metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2023-10-15T14:10:38.628754Z","iopub.status.busy":"2023-10-15T14:10:38.628494Z","iopub.status.idle":"2023-10-15T14:10:42.834203Z","shell.execute_reply":"2023-10-15T14:10:42.833428Z","shell.execute_reply.started":"2023-10-15T14:10:38.628722Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","# 主要用来 excel 表格的操作, 实现数据集的读取\n","import pandas as pd\n","# pd.options.plotting.backend = \"plotly\"\n","\n","import random\n","from glob import glob\n","import os, shutil\n","# tqdm 库的功能是提供一个快速，可扩展的 Python 进度条，可以在 Python 长循环中添加一个进度提示信息\n","from tqdm.notebook import tqdm\n","tqdm.pandas ()\n","import time\n","import copy\n","from collections import defaultdict\n","\n","# 强制回收垃圾, 释放空间\n","import gc\n","\n","# 结合 wandb 打印训练过程中一些指标的变化 \n","from IPython import display as ipd\n","\n","# 图像可视化\n","import cv2\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Rectangle\n","\n","# 用来 k 折交叉检验\n","from sklearn.model_selection import StratifiedGroupKFold\n","\n","# Pytorch 常用库\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda import amp\n","\n","# 用于数据增强\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","from joblib import Parallel, delayed\n","\n","# 终端输出是可以输出不同颜色的文字\n","from colorama import Fore, Back, Style\n","c_  = Fore.GREEN\n","sr_ = Style.RESET_ALL\n","\n","import warnings\n","warnings.filterwarnings (\"ignore\")\n","\n","# For descriptive error messages\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""]},{"cell_type":"markdown","metadata":{},"source":["# ⭐ WandB"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:10:42.835828Z","iopub.status.busy":"2023-10-15T14:10:42.835421Z","iopub.status.idle":"2023-10-15T14:10:46.040915Z","shell.execute_reply":"2023-10-15T14:10:46.040055Z","shell.execute_reply.started":"2023-10-15T14:10:42.835787Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcharming\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\pc/.netrc\n"]}],"source":["import wandb\n","# from kaggle_secrets import UserSecretsClient\n","# user_secrets = UserSecretsClient ()\n","# api_key = user_secrets.get_secret (\"WANDB\")\n","wandb.login (key = \"f89bb5c977a0726d4d4727415427dd5eb8359124\")\n","anonymous = None"]},{"cell_type":"markdown","metadata":{},"source":["# ⚙️ Configuration \n","把该项目所用到的参数都包含到 $CFG$ 类中"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:10:46.044605Z","iopub.status.busy":"2023-10-15T14:10:46.044105Z","iopub.status.idle":"2023-10-15T14:10:46.194146Z","shell.execute_reply":"2023-10-15T14:10:46.193172Z","shell.execute_reply.started":"2023-10-15T14:10:46.044566Z"},"trusted":true},"outputs":[],"source":["class CFG:\n","    seed          = 101\n","    debug         = False # set debug=False for Full Training\n","    exp_name      = 'Unet-For-UWMGI'\n","    comment       = 'Unet-resnet18-224x224-UWMGI'\n","    model_name    = 'Unet'\n","#     backbone      = 'efficientnet-b1' # 原 backbone\n","    backbone      = 'resnet18'\n","    train_bs      = 64\n","    valid_bs      = train_bs * 2\n","    img_size      = [224, 224]\n","    epochs        = 15\n","    lr            = 1e-3\n","    scheduler     = 'CosineAnnealingLR'\n","    min_lr        = 1e-6\n","    T_max         = int (30000 / train_bs * epochs) + 50\n","    T_0           = 25\n","    warmup_epochs = 0\n","    wd            = 1e-6\n","    n_accumulate  = max (1, 32 // train_bs)\n","    n_fold        = 5\n","    num_classes   = 3\n","    # device        = torch.device (\"cuda:0\" if torch.cuda.is_available () else \"cpu\")\n","    device = \"cpu\"\n"]},{"cell_type":"markdown","metadata":{},"source":["# ❗ Reproducibility"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:10:46.198056Z","iopub.status.busy":"2023-10-15T14:10:46.197698Z","iopub.status.idle":"2023-10-15T14:10:46.274217Z","shell.execute_reply":"2023-10-15T14:10:46.273301Z","shell.execute_reply.started":"2023-10-15T14:10:46.198018Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["> SEEDING DONE\n"]}],"source":["def set_seed (seed = 42):\n","    '''\n","        初始化各个随机种子为同一值, \n","        保证每次执行程序的运行情况都相同\n","    '''\n","    np.random.seed (seed)\n","    random.seed (seed)\n","    torch.manual_seed (seed)\n","    torch.cuda.manual_seed (seed)\n","    # When running on the CuDNN backend, two further options must be set\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # Set a fixed value for the hash seed\n","    os.environ['PYTHONHASHSEED'] = str (seed)\n","    print ('> SEEDING DONE')\n","    \n","set_seed (CFG.seed)"]},{"cell_type":"markdown","metadata":{},"source":["# 📖 Meta Data\n","数据集中有部分数据是只有图像没有掩码的 (即没有标签)。\n","由于类别共三种, 所以表格中每个样本均有三项, 每一项之间只有 $class$ 不同, 对应的图像地址和掩码图像地址都一样, 且一张掩码图像中包含了全部三种器官的掩码。"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:10:46.276483Z","iopub.status.busy":"2023-10-15T14:10:46.275904Z","iopub.status.idle":"2023-10-15T14:10:48.123186Z","shell.execute_reply":"2023-10-15T14:10:48.122248Z","shell.execute_reply.started":"2023-10-15T14:10:46.276445Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv('./uwmgi-mask-dataset/train.csv')\n","# 填充表格中空着的 segmentation 项\n","df['segmentation'] = df.segmentation.fillna('') \n","# 把掩码对应的图片地址修改成对应的 npy 地址\n","df['mask_path'] = df.mask_path.str.replace('/png/','/np').str.replace('.png','.npy') \n","# 计算每一个样本的掩码的长度, 用来判断该样本是否有掩码\n","df['rle_len'] = df.segmentation.map (len) \n","# 计算每个样本对应的掩码长度之和, 只要有一个及以上类别存在掩码, 即判断该图像有掩码, 同时把样本对应的三项归为一项了\n","df2 = df.groupby (['id'])['rle_len'].agg (sum).to_frame ().reset_index () \n","# 添加 empty 列, 说明该样本的状态 (即是否有掩码)\n","df2['empty'] = (df2.rle_len == 0) \n","df2 = df2.drop (columns = ['rle_len'])\n","# 删除无用信息\n","df = df.drop (columns = ['class', 'segmentation', 'day', 'slice', 'height', 'width', 'rle_len']) \n","# 三项归为一项\n","df = df.drop_duplicates (subset = ['id'], keep = 'first') \n","# 获取 empty 状态\n","df = df.merge (df2, on = ['id']) "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:10:48.124622Z","iopub.status.busy":"2023-10-15T14:10:48.124369Z","iopub.status.idle":"2023-10-15T14:10:50.795659Z","shell.execute_reply":"2023-10-15T14:10:50.794665Z","shell.execute_reply.started":"2023-10-15T14:10:48.124589Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40630887cf5c41a48939a296e49f5689","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/38496 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["                         id  case  \\\n","0  case123_day20_slice_0001   123   \n","1  case123_day20_slice_0002   123   \n","2  case123_day20_slice_0003   123   \n","3  case123_day20_slice_0004   123   \n","4  case123_day20_slice_0005   123   \n","\n","                                          image_path  \\\n","0  /kaggle/input/uw-madison-gi-tract-image-segmen...   \n","1  /kaggle/input/uw-madison-gi-tract-image-segmen...   \n","2  /kaggle/input/uw-madison-gi-tract-image-segmen...   \n","3  /kaggle/input/uw-madison-gi-tract-image-segmen...   \n","4  /kaggle/input/uw-madison-gi-tract-image-segmen...   \n","\n","                                           mask_path  empty  \n","0  /kaggle/input/uwmgi-mask-dataset/np/uw-madison...   True  \n","1  /kaggle/input/uwmgi-mask-dataset/np/uw-madison...   True  \n","2  /kaggle/input/uwmgi-mask-dataset/np/uw-madison...   True  \n","3  /kaggle/input/uwmgi-mask-dataset/np/uw-madison...   True  \n","4  /kaggle/input/uwmgi-mask-dataset/np/uw-madison...   True  \n","37851\n","empty\n","True     21553\n","False    16298\n","Name: count, dtype: int64\n"]}],"source":["# 删除脏数据\n","Case138_Day0 = [i for i in range (76, 145)]\n","Case85_Day23 = [119,120,121,122,123,124]\n","Case90_Day29 = [115,116,117,118,119]\n","Case133_Day25 = [111,112,113]\n","Case7 = []\n","Case43 = []\n","Case81 = []\n","Case85 = []\n","Case90 = []\n","Case133 = []\n","Case138 = []\n","for i,row in tqdm (df.iterrows (), total = len (df)) :\n","    if row.id.rsplit (\"_\",2)[0] == 'case7_day0':\n","        Case7.append (i)\n","    elif row.id.rsplit (\"_\",2)[0] == 'case43_day18' or row.id.rsplit (\"_\",2)[0] == 'case43_day26' :\n","        Case43.append (i)\n","    elif row.id.rsplit (\"_\",2)[0] == 'case81_day30' :\n","        Case81.append (i)\n","    elif row.id.rsplit (\"_\",2)[0] == 'case138_day0' :\n","        if int (row.id.rsplit (\"_\",1)[-1]) in Case138_Day0 :\n","            Case138.append (i)\n","df.drop (index = Case7 + Case43 + Case81 + Case138 ,inplace = True)\n","df = df.reset_index (drop = True)\n","\n","print (df.head ())\n","print (len (df))\n","print (df['empty'].value_counts())"]},{"cell_type":"markdown","metadata":{},"source":["# 🔨 Utility\n","这里主要实现的功能是根据文件路径加载 $np$ 格式的样本和标签、输入 $np$ 格式的样本和标签(可选)并展示"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:10:50.797377Z","iopub.status.busy":"2023-10-15T14:10:50.797116Z","iopub.status.idle":"2023-10-15T14:10:50.848917Z","shell.execute_reply":"2023-10-15T14:10:50.848056Z","shell.execute_reply.started":"2023-10-15T14:10:50.797343Z"},"trusted":true},"outputs":[],"source":["def load_img (path):\n","    '''\n","        根据文件路径读取图像, 并复制成三份, 成三通道图像\n","    '''\n","    img = cv2.imread (path, cv2.IMREAD_UNCHANGED)\n","    img = np.tile (img[...,None], [1, 1, 3]) # gray to rgb\n","    img = img.astype ('float32') # original is uint16\n","    mx = np.max (img)\n","    if mx:\n","        img /= mx # scale image to [0, 1]\n","    return img\n","\n","def load_msk (path):\n","    '''\n","        根据文件路径读取掩码图像 (已经处理成 numpy 格式了)\n","    '''\n","    msk = np.load (path)\n","    msk = msk.astype('float32')\n","    msk /= 255.0\n","    return msk\n","    \n","def png2tensor (img_path, msk_path = None) :\n","    '''\n","        给定图片路径、掩码路径, 转为 tensor 类型\n","    '''\n","    img = load_img (img_path)\n","    if msk_path == None :\n","        data = data_transforms['valid'] (image = img)\n","        img = data['image']\n","        img = torch.tensor (np.transpose (img, (2, 0, 1)))\n","        return img\n","    else :\n","        msk = load_msk (msk_path)\n","        data = data_transforms['valid'] (image = img, mask = msk)\n","        img = data['image']\n","        msk = data['mask']\n","        img = torch.tensor (np.transpose (img, (2, 0, 1)))\n","        msk = torch.tensor (np.transpose (msk, (2, 0, 1)))\n","        return img, msk\n","\n","def show_img (img, mask = None):\n","    ''' \n","        展示图像, 如果输入了掩码图像则一起展示\n","        输入的图像要提前处理成 numpy 格式\n","    '''\n","#     用于医学影像增强\n","#     clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n","#     img = clahe.apply(img)\n","#     plt.figure(figsize=(10,10))\n","    plt.imshow (img, cmap = 'bone')\n","    \n","    if mask is not None:\n","        plt.imshow (mask, alpha = 0.5) # alpha 参数, 透明度\n","        handles = [Rectangle ((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n","        labels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n","        plt.legend (handles, labels) # 标签与掩码颜色相对应\n","    plt.axis('off')"]},{"cell_type":"markdown","metadata":{},"source":["# 📁 Create Folds\n","$K$ 折交叉检验, 把整个数据集分成 $n \\_ fold$ 份, 训练时选择其中一份作为测试集, 其余的作为训练集"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:10:50.851172Z","iopub.status.busy":"2023-10-15T14:10:50.850660Z","iopub.status.idle":"2023-10-15T14:10:51.015180Z","shell.execute_reply":"2023-10-15T14:10:51.014284Z","shell.execute_reply.started":"2023-10-15T14:10:50.851136Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(30144,) (7707,)\n","(30107,) (7744,)\n","(29483,) (8368,)\n","(29323,) (8528,)\n","(32347,) (5504,)\n"]},{"data":{"text/plain":["fold  empty\n","0.0   False    3366\n","      True     4341\n","1.0   False    3317\n","      True     4427\n","2.0   False    3557\n","      True     4811\n","3.0   False    3754\n","      True     4774\n","4.0   False    2304\n","      True     3200\n","Name: id, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["skf = StratifiedGroupKFold (n_splits = CFG.n_fold, shuffle = True, random_state = CFG.seed)\n","for fold, (train_idx, val_idx) in enumerate (skf.split (df, df['empty'], groups = df[\"case\"])):\n","    df.loc[val_idx, 'fold'] = fold\n","    print (train_idx.shape, val_idx.shape)\n","display (df.groupby(['fold','empty'])['id'].count())"]},{"cell_type":"markdown","metadata":{},"source":["# 🍚 Dataset\n","$pytorch$ 的 $Dataset$ 类可自定义, 需要实现 $\\_ \\_ len \\_ \\_$ 和 $\\_ \\_ getitem \\_ \\_$ 方法, 前者用来获取数据及大小, 后者用于指定下标, 返回对应的样本"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:10:51.017226Z","iopub.status.busy":"2023-10-15T14:10:51.016496Z","iopub.status.idle":"2023-10-15T14:10:51.071939Z","shell.execute_reply":"2023-10-15T14:10:51.071043Z","shell.execute_reply.started":"2023-10-15T14:10:51.017188Z"},"trusted":true},"outputs":[],"source":["class BuildDataset(torch.utils.data.Dataset):\n","    '''\n","        数据集总体可以分为两类, 有标签和无标签\n","        对于训练集, 需要进行一系列数据增强的操作, 包括图片的旋转、水平翻转\n","        对于测试集和验证集, 则不需要数据增强\n","        所以需要设计两种 transforms\n","        训练集、测试集、验证集均需要固定图片尺寸 (224, 224)\n","    '''\n","    def __init__(self, df, label = True, transforms = None) :\n","        self.df         = df\n","        self.label      = label\n","        self.img_paths  = df['image_path'].tolist()\n","        self.msk_paths  = df['mask_path'].tolist()\n","        self.transforms = transforms\n","        \n","    def __len__(self) :\n","        return len (self.df)\n","    \n","    def __getitem__(self, index) :\n","        img_path  = self.img_paths[index]\n","        img = []\n","        img = load_img (img_path)\n","        \n","        if self.label :\n","            msk_path = self.msk_paths[index]\n","            msk = load_msk (msk_path)\n","            if self.transforms:\n","                data = self.transforms (image = img, mask = msk)\n","                img  = data['image']\n","                msk  = data['mask']\n","            img = np.transpose (img, (2, 0, 1))\n","            msk = np.transpose (msk, (2, 0, 1))\n","            return torch.tensor (img), torch.tensor (msk)\n","        else :\n","            if self.transforms :\n","                data = self.transforms (image = img)\n","                img  = data['image']\n","            img = np.transpose (img, (2, 0, 1))\n","            return torch.tensor (img)"]},{"cell_type":"markdown","metadata":{},"source":["# 🌈 Augmentations"]},{"cell_type":"code","execution_count":12,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-10-15T14:10:51.074186Z","iopub.status.busy":"2023-10-15T14:10:51.073682Z","iopub.status.idle":"2023-10-15T14:10:51.126835Z","shell.execute_reply":"2023-10-15T14:10:51.125878Z","shell.execute_reply.started":"2023-10-15T14:10:51.074140Z"},"trusted":true},"outputs":[],"source":["data_transforms = {\n","    \"train\": A.Compose ([\n","        # 固定图像尺寸\n","        A.Resize (*CFG.img_size, interpolation = cv2.INTER_NEAREST),\n","        # 随机水平翻转\n","        A.HorizontalFlip (p = 0.5), \n","#         A.VerticalFlip(p=0.5),\n","        # 随机平移、缩放、旋转\n","        A.ShiftScaleRotate (shift_limit = 0.0625, scale_limit = 0.05, rotate_limit = 10, p = 0.5), \n","        A.OneOf ([\n","            # 以下两种操作以 p 的概率随机选择其中一种\n","            # 网格畸变\n","            A.GridDistortion (num_steps = 5, distort_limit = 0.05, p = 1.0), \n","#             A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n","            # 弹性变换, 扭曲图像的同时保持图像的连续性\n","            A.ElasticTransform (alpha = 1, sigma = 50, alpha_affine = 50, p = 1.0)\n","#             A.ElasticTransform (alpha = 20, sigma = 5, alpha_affine = 20, p = 1.0)\n","        ], p = 0.25),\n","        # 对图片进行随机遮挡, 遮挡区域用固定值或者随机值填充\n","        A.CoarseDropout (max_holes = 8, max_height = CFG.img_size[0] // 20, \n","                        max_width = CFG.img_size[1] // 20, min_holes = 5, \n","                        fill_value = 0, mask_fill_value = 0, p = 0.5),\n","        ], p = 1.0),\n","    \n","    \"valid\": A.Compose ([\n","        A.Resize (*CFG.img_size, interpolation = cv2.INTER_NEAREST),\n","        ], p = 1.0)\n","}"]},{"cell_type":"markdown","metadata":{},"source":["# 🍰 DataLoader"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:10:51.128981Z","iopub.status.busy":"2023-10-15T14:10:51.128439Z","iopub.status.idle":"2023-10-15T14:11:04.580932Z","shell.execute_reply":"2023-10-15T14:11:04.580156Z","shell.execute_reply.started":"2023-10-15T14:10:51.128939Z"},"trusted":true},"outputs":[],"source":["def DataLoad (fold) :\n","    '''\n","        K 折交叉验证, 指定验证集为哪一折, 划分训练集和验证集\n","    '''\n","    # drop 参数表示是否删除原来的索引列\n","    train_df = df.query (\"fold!=@fold & empty==0\").reset_index (drop = True)\n","    valid_df = df.query (\"fold==@fold & empty==0\").reset_index (drop = True)\n","    train_dataset = BuildDataset (train_df, transforms = data_transforms['train'])\n","    valid_dataset = BuildDataset (valid_df, transforms = data_transforms['valid'])\n","\n","    # pin_memory 参数表示是否将加载的数据常驻内存\n","    # drop_last 参数表示是否丢弃最后一个批次 (可能不满 batch_size 个样本)\n","    train_loader = DataLoader (train_dataset, batch_size = CFG.train_bs, num_workers = 4, \n","                               shuffle = True, pin_memory = True, drop_last = False)\n","    valid_loader = DataLoader (valid_dataset, batch_size = CFG.valid_bs, num_workers = 4, \n","                               shuffle = False, pin_memory = True)\n","    \n","    return train_loader, valid_loader\n","\n","train_loader, valid_loader = DataLoad (fold = 0)\n","imgs, msks = next (iter (train_loader))\n","imgs.size (), msks.size ()"]},{"cell_type":"markdown","metadata":{},"source":["# 📈 Visualization\n","展示一个批次内部分图像及其掩码"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-10-15T14:11:04.585421Z","iopub.status.busy":"2023-10-15T14:11:04.585096Z","iopub.status.idle":"2023-10-15T14:11:05.466636Z","shell.execute_reply":"2023-10-15T14:11:05.465976Z","shell.execute_reply.started":"2023-10-15T14:11:04.585395Z"},"trusted":true},"outputs":[],"source":["def plot_batch (imgs, msks, size = 3) :\n","    '''\n","        输入的 tensor 类型的数据, 要先把通道维度换到最后一维, 然后转成 numpy 类型\n","    '''\n","    plt.figure (figsize = (5 * size, 5))\n","    for idx in range (size) :\n","        plt.subplot (1, size, idx + 1)\n","        img = imgs[idx,].permute ((1, 2, 0)).numpy () * 255.0\n","        img = img.astype ('uint8')\n","        msk = msks[idx,].permute ((1, 2, 0)).numpy () * 255.0\n","        show_img (img, msk)\n","    plt.tight_layout ()\n","    plt.show ()\n","\n","plot_batch (imgs, msks, size = 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:11:05.467805Z","iopub.status.busy":"2023-10-15T14:11:05.467571Z","iopub.status.idle":"2023-10-15T14:11:05.690682Z","shell.execute_reply":"2023-10-15T14:11:05.689711Z","shell.execute_reply.started":"2023-10-15T14:11:05.467771Z"},"trusted":true},"outputs":[{"data":{"text/plain":["45"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["import gc\n","# 强制执行一次垃圾回收, 检测并释放不再被引用的对象所占用的内存空间\n","gc.collect ()"]},{"cell_type":"markdown","metadata":{},"source":["# 📦 Model\n","模型的搭建, 直接使用了 $smp$ 库中的 $unet$ 模型。\n","可以选择模型的编码器、模型的预训练，设置输入通道数、分类数"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:11:05.692530Z","iopub.status.busy":"2023-10-15T14:11:05.692101Z","iopub.status.idle":"2023-10-15T14:11:11.208458Z","shell.execute_reply":"2023-10-15T14:11:11.207646Z","shell.execute_reply.started":"2023-10-15T14:11:05.692494Z"},"trusted":true},"outputs":[],"source":["import segmentation_models_pytorch as smp\n","\n","def build_model (backbone = CFG.backbone):\n","#     model = smp.Unet(\n","#         encoder_name = CFG.backbone,      # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n","#         encoder_weights = \"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n","#         in_channels = 3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n","#         classes = CFG.num_classes,        # model output channels (number of classes in your dataset)\n","#         activation = None,\n","#     )\n","#     segmentation_head = dict (\n","#         in_channels = 512,\n","#         out_channels = 3,\n","#         activation = None,\n","#         kernel_size = 3,\n","#         upsampling = \"upsample\",\n","#         upsample_scale = 2,\n","#     )\n","    model = smp.Unet (\n","        # 更换成 resnet50\n","        encoder_name = backbone, \n","        # 定义编码器网络深度, 设为 4，加速训练过程\n","#         encoder_depth = 4,\n","        # 不设预训练权重, 从零开始训练!\n","        encoder_weights = None,\n","        # 没有 decoder_name, 由模型框架 Unet 决定\n","        # 给定图片是单通道的, 读入时叠加成三通道\n","        in_channels = 3, \n","        # 分类类别参数, 对于 UWMGI 数据集是 3\n","        classes = CFG.num_classes,\n","        activation = None,\n","#         segmentation_head = segmentation_head,\n","    )\n","    model.to (CFG.device)\n","    return model\n","\n","def load_model (backbone, path) :\n","    '''\n","        用于测试模型前加载训练过程中表现最好的模型\n","    '''\n","    model = build_model (backbone)\n","    model.load_state_dict (torch.load (path, map_location = torch.device('cpu')))\n","    model.eval ()\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["# 🔧 Loss Function\n","$Tversky$ 指数 $=$ $S(P, G, \\alpha, \\beta) = \\frac{|P \\cap G|}{|P \\cap G| + \\alpha |P \\setminus G| + \\beta |G \\setminus P|}$, <br/> 当 $\\alpha = \\beta = 0.5$ 时, $Tversky$ 系数等价于 $Dice$ 系数;\n","\n","$Jaccard$ 系数与 $IOU$ 系数的计算公式是相同的, 只是应用场景不尽相同, 才有不同的名字。<br/>\n","$Jaccard$ 用于比较样本集的相似性与多样性，是一种统计量；<br/>\n","$IOU$ 系数通常用于比较图像分割等任务中预测框与真实框的接近程度，是一种评价指标。<br/>\n","$J(P, G) = IOU(P, G) = \\frac{|P \\cap G|}{|P \\cup G|}$\n","\n","$LovaszLoss$ 系数就是 $1 - Tversky$..."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:11:11.210070Z","iopub.status.busy":"2023-10-15T14:11:11.209658Z","iopub.status.idle":"2023-10-15T14:11:11.274967Z","shell.execute_reply":"2023-10-15T14:11:11.274307Z","shell.execute_reply.started":"2023-10-15T14:11:11.210032Z"},"trusted":true},"outputs":[],"source":["BCELoss     = smp.losses.SoftBCEWithLogitsLoss ()\n","TverskyLoss = smp.losses.TverskyLoss (mode = 'multilabel', log_loss = False)\n","\n","def dice_coef (y_true, y_pred, thr = 0.5, dim = (2,3), epsilon = 0.001) :\n","    '''\n","        图像 A, B 的 dice 系数等于 A 和 B 的掩码区域的交集的面积大小乘以 2\n","        再除以 A 的掩码区域面积与 B 的掩码区域面积的和\n","        可以用来衡量两个图像的相似程度\n","    '''\n","    y_true = y_true.to (torch.float32)\n","    y_pred = (y_pred > thr).to (torch.float32)\n","    inter = (y_true * y_pred).sum (dim = dim)\n","    den = y_true.sum (dim = dim) + y_pred.sum (dim = dim)\n","    dice = ((2 * inter + epsilon) / (den+epsilon)).mean (dim = (1,0))\n","    return dice\n","\n","def iou_coef (y_true, y_pred, thr = 0.5, dim = (2, 3), epsilon = 0.001) :\n","    '''\n","        iou 系数与 dice 系数类似, 计算公式中分子均为两图像的交集, \n","        dice 系数的计算公式的分母为两图像面积和\n","        iou 系数的计算公式的分母为两图像并集\n","    '''\n","    y_true = y_true.to (torch.float32)\n","    y_pred = (y_pred > thr).to (torch.float32)\n","    inter = (y_true * y_pred).sum (dim = dim)\n","    union = (y_true + y_pred - y_true * y_pred).sum (dim = dim)\n","    iou = ((inter + epsilon) / (union + epsilon)).mean (dim = (1,0))\n","    return iou\n","\n","def criterion (y_pred, y_true) :\n","    return 0.5 * BCELoss (y_pred, y_true) + 0.5 * TverskyLoss (y_pred, y_true)"]},{"cell_type":"markdown","metadata":{},"source":["# 🚄 Training Function\n","用到了自动混合精度训练和损失放大<br/>\n","$tqdm$ 库用于展示模型训练的进度条"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:11:11.276857Z","iopub.status.busy":"2023-10-15T14:11:11.276184Z","iopub.status.idle":"2023-10-15T14:11:11.346333Z","shell.execute_reply":"2023-10-15T14:11:11.345509Z","shell.execute_reply.started":"2023-10-15T14:11:11.276820Z"},"trusted":true},"outputs":[],"source":["def train_one_epoch (model, optimizer, scheduler, dataloader, device, epoch) :\n","    # model.train () 与 model.eval () 主要影响网络中 BatchNorm 层和 Dropout 层\n","    # 前者启用, 后者不启用; model.eval () 模式下不会进行反向传播, 但是梯度的计算照常进行\n","    # model.eval () 配合 torch.no_grad () 使用, 加速计算过程、节省显存空间\n","    model.train ()\n","    # 创建一个 GradScaler 对象, 可以在迭代过程中动态估计损失放大的倍数\n","    scaler = amp.GradScaler ()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    # 将一个可迭代对象作为参数传入，然后返回一个包装后的可迭代对象，\n","    # 可以像平常一样对其进行迭代，每次请求一个值时，都会打印一个进度条。\n","    pbar = tqdm (enumerate (dataloader), total = len (dataloader), desc = 'Train ')\n","    for step, (images, masks) in pbar:         \n","        images = images.to (device, dtype = torch.float)\n","        masks  = masks.to (device, dtype = torch.float)\n","        \n","        batch_size = images.size (0)\n","        \n","        # 前向传播过程中自动混合精度训练\n","        with amp.autocast (enabled = True):\n","            y_pred = model (images)\n","            loss   = criterion (y_pred, masks)\n","            # n_accumulate 参数的含义是每若干个批次后进行一次梯度更新\n","            loss   = loss / CFG.n_accumulate\n","        # 放大损失、反向传播\n","        scaler.scale (loss).backward ()\n","    \n","        if (step + 1) % CFG.n_accumulate == 0 :\n","            # 根据原放大倍数，梯度更新时缩小相应的倍数\n","            scaler.step (optimizer)\n","            # 更新损失放大的倍数\n","            scaler.update ()\n","\n","            optimizer.zero_grad ()\n","\n","            if scheduler is not None :\n","                # 更新学习率\n","                scheduler.step ()\n","                \n","        running_loss += (loss.item () * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        mem = torch.cuda.memory_reserved () / 1E9 if torch.cuda.is_available () else 0\n","        current_lr = optimizer.param_groups[0]['lr']\n","        pbar.set_postfix (train_loss = f'{epoch_loss : 0.4f}',\n","                        lr = f'{current_lr : 0.5f}',\n","                        gpu_mem = f'{mem : 0.2f} GB')\n","    torch.cuda.empty_cache ()\n","    gc.collect ()\n","    \n","    return epoch_loss"]},{"cell_type":"markdown","metadata":{},"source":["# 👀 Validation Function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:11:11.348083Z","iopub.status.busy":"2023-10-15T14:11:11.347596Z","iopub.status.idle":"2023-10-15T14:11:11.415190Z","shell.execute_reply":"2023-10-15T14:11:11.414423Z","shell.execute_reply.started":"2023-10-15T14:11:11.348025Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad ()\n","def valid_one_epoch (model, dataloader, device, epoch):\n","    model.eval ()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    val_scores = []\n","    \n","    pbar = tqdm (enumerate (dataloader), total = len (dataloader), desc = 'Valid ')\n","    for step, (images, masks) in pbar :\n","        images  = images.to (device, dtype = torch.float)\n","        masks   = masks.to (device, dtype = torch.float)\n","        \n","        batch_size = images.size (0)\n","        \n","        y_pred  = model (images)\n","        loss    = criterion (y_pred, masks)\n","        \n","        running_loss += (loss.item () * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        y_pred = nn.Sigmoid () (y_pred)\n","        val_dice = dice_coef (masks, y_pred).cpu ().detach ().numpy ()\n","        val_jaccard = iou_coef (masks, y_pred).cpu ().detach ().numpy ()\n","        val_scores.append ([val_dice, val_jaccard])\n","        \n","        mem = torch.cuda.memory_reserved () / 1E9 if torch.cuda.is_available() else 0\n","        current_lr = optimizer.param_groups[0]['lr']\n","        pbar.set_postfix (valid_loss = f'{epoch_loss : 0.4f}',\n","                        lr = f'{current_lr : 0.5f}',\n","                        gpu_memory = f'{mem : 0.2f} GB')\n","    val_scores  = np.mean (val_scores, axis = 0)\n","    torch.cuda.empty_cache ()\n","    gc.collect()\n","    \n","    return epoch_loss, val_scores"]},{"cell_type":"markdown","metadata":{},"source":["# 🏃 Run Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:11:11.417040Z","iopub.status.busy":"2023-10-15T14:11:11.416577Z","iopub.status.idle":"2023-10-15T14:11:11.487353Z","shell.execute_reply":"2023-10-15T14:11:11.486568Z","shell.execute_reply.started":"2023-10-15T14:11:11.416986Z"},"trusted":true},"outputs":[],"source":["def run_training (model, optimizer, scheduler, device, num_epochs) :\n","    '''\n","        这里主要做一些记录训练日志、保存最优模型等工作\n","    '''\n","    # wandb 自动记录 PyTorch 模型的权重、偏置和梯度, log_freq 设置记录的频率 (每 log_freq 批次记录一次)\n","    wandb.watch (model, log_freq = 100)\n","    \n","    # 打印 GPU 的名字\n","    if torch.cuda.is_available ():\n","        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name ()))\n","    \n","    start = time.time ()\n","    best_model_wts = copy.deepcopy (model.state_dict())\n","    best_dice      = -np.inf\n","    best_epoch     = -1\n","    history = defaultdict (list)\n","    \n","    for epoch in range (1, num_epochs + 1): \n","        gc.collect ()\n","        print (f'Epoch {epoch} / {num_epochs}', end = '')\n","        train_loss = train_one_epoch (model, optimizer, scheduler, \n","                                           dataloader = train_loader, \n","                                           device = CFG.device, epoch = epoch)\n","        \n","        val_loss, val_scores = valid_one_epoch (model, valid_loader, \n","                                                 device = CFG.device, \n","                                                 epoch = epoch)\n","        val_dice, val_jaccard = val_scores\n","    \n","        history['Train Loss'].append (train_loss)\n","        history['Valid Loss'].append (val_loss)\n","        history['Valid Dice'].append (val_dice)\n","        history['Valid Jaccard'].append (val_jaccard)\n","        \n","        # Log the metrics\n","        wandb.log ({\"Train Loss\" : train_loss, \n","                   \"Valid Loss\" : val_loss,\n","                   \"Valid Dice\" : val_dice,\n","                   \"Valid Jaccard\" : val_jaccard,\n","                   \"LR\" : scheduler.get_last_lr ()[0]})\n","        \n","        print(f'Valid Dice: {val_dice : 0.4f} | Valid Jaccard: {val_jaccard : 0.4f}')\n","        \n","        # deep copy the model\n","        if val_dice >= best_dice:\n","            print(f\"{c_}Valid Score Improved ({best_dice:0.4f} ---> {val_dice:0.4f})\")\n","            best_dice    = val_dice\n","            best_jaccard = val_jaccard\n","            best_epoch   = epoch\n","            run.summary[\"Best Dice\"]    = best_dice\n","            run.summary[\"Best Jaccard\"] = best_jaccard\n","            run.summary[\"Best Epoch\"]   = best_epoch\n","            best_model_wts = copy.deepcopy (model.state_dict ())\n","            PATH = f\"best_epoch-{fold:02d}.bin\"\n","            torch.save (model.state_dict (), PATH)\n","            # Save a model file from the current directory\n","            wandb.save (PATH)\n","            print (f\"Model Saved{sr_}\")\n","            \n","        last_model_wts = copy.deepcopy (model.state_dict ())\n","        PATH = f\"last_epoch-{fold : 02d}.bin\"\n","        torch.save (model.state_dict (), PATH)\n","            \n","        print (); print ()\n","    \n","    end = time.time()\n","    time_elapsed = end - start\n","    print ('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format (\n","        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n","    print (\"Best Score: {:.4f}\".format (best_jaccard))\n","    \n","    # load best model weights\n","    model.load_state_dict (best_model_wts)\n","    \n","    return model, history"]},{"cell_type":"markdown","metadata":{},"source":["# 🔍 Optimizer\n","$torch.optim.CosineAnnealingLR ()$ 方法是一个用于设置学习率的调度器，它可以根据一个余弦退火的策略，动态地调整优化器的学习率。它的原理是在每个周期内，将学习率从一个最大值降低到一个最小值，然后在下一个周期内重复这个过程。这样可以避免学习率过大或过小导致的收敛困难或局部最优;\n","\n","$torch.optim.CosineAnnealingWarmRestarts ()$ 与 $torch.optim.CosineAnnealingLR ()$ 类似, 主要区别是前者的每个周期长度是动态调整的, 后者是固定的;\n","\n","$torch.optim.ReduceLROnPlateau ()$ 方法是一个用于设置学习率的调度器，它可以根据一个指标（如损失函数或准确率）是否停止改善，来动态地调整优化器的学习率。可以指定学习率的衰减因子，耐心值，阈值，冷却时间，最小学习率等选项;\n","\n","$torch.optim.ExponentialLR ()$ 方法是一个用于设置学习率的调度器，它可以根据一个指数衰减的策略，动态地调整优化器的学习率。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:11:11.489104Z","iopub.status.busy":"2023-10-15T14:11:11.488620Z","iopub.status.idle":"2023-10-15T14:11:11.551023Z","shell.execute_reply":"2023-10-15T14:11:11.550274Z","shell.execute_reply.started":"2023-10-15T14:11:11.489070Z"},"trusted":true},"outputs":[],"source":["def fetch_scheduler (optimizer):\n","    if CFG.scheduler == 'CosineAnnealingLR' :\n","        scheduler = lr_scheduler.CosineAnnealingLR (optimizer, T_max = CFG.T_max, \n","                                                   eta_min = CFG.min_lr)\n","    elif CFG.scheduler == 'CosineAnnealingWarmRestarts' :\n","        scheduler = lr_scheduler.CosineAnnealingWarmRestarts (optimizer, T_0 = CFG.T_0, \n","                                                             eta_min = CFG.min_lr)\n","    elif CFG.scheduler == 'ReduceLROnPlateau' :\n","        scheduler = lr_scheduler.ReduceLROnPlateau (optimizer,\n","                                                   mode = 'min',\n","                                                   factor = 0.1,\n","                                                   patience = 7,\n","                                                   threshold = 0.0001,\n","                                                   min_lr = CFG.min_lr,)\n","    elif CFG.scheduer == 'ExponentialLR' :\n","        scheduler = lr_scheduler.ExponentialLR (optimizer, gamma = 0.85)\n","    elif CFG.scheduler == None:\n","        return None\n","        \n","    return scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:11:11.552765Z","iopub.status.busy":"2023-10-15T14:11:11.552294Z","iopub.status.idle":"2023-10-15T14:11:13.803508Z","shell.execute_reply":"2023-10-15T14:11:13.802740Z","shell.execute_reply.started":"2023-10-15T14:11:11.552730Z"},"trusted":true},"outputs":[],"source":["# model = build_model ()\n","# optimizer = optim.Adam (model.parameters (), lr = CFG.lr, weight_decay = CFG.wd)\n","# scheduler = fetch_scheduler (optimizer)\n"]},{"cell_type":"markdown","metadata":{},"source":["# 🚅 Training"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-10-15T14:11:13.805248Z","iopub.status.busy":"2023-10-15T14:11:13.804838Z","iopub.status.idle":"2023-10-15T14:11:13.866731Z","shell.execute_reply":"2023-10-15T14:11:13.865959Z","shell.execute_reply.started":"2023-10-15T14:11:13.805203Z"},"trusted":true},"outputs":[],"source":["# for fold in range (1):\n","#     print (f'#'*15)\n","#     print (f'### Fold: {fold}')\n","#     print (f'#'*15)\n","#     run = wandb.init (project ='Unet-For-UWMGI', \n","#                      config = {k:v for k, v in dict(vars(CFG)).items() if '__' not in k},\n","#                      anonymous = anonymous,\n","#                      name = f\"fold-{fold}|dim-{CFG.img_size[0]}x{CFG.img_size[1]}|model-{CFG.model_name}\",\n","#                      group = CFG.comment,\n","#                     )\n","#     train_loader, valid_loader = DataLoad (fold = fold)\n","#     model     = build_model ()\n","#     optimizer = optim.Adam (model.parameters(), lr = CFG.lr, weight_decay = CFG.wd)\n","#     scheduler = fetch_scheduler (optimizer)\n","#     model, history = run_training (model, optimizer, scheduler,\n","#                                   device = CFG.device,\n","#                                   num_epochs = CFG.epochs)\n","#     run.finish ()\n","#     display (ipd.IFrame (run.url, width = 1000, height = 720))"]},{"cell_type":"markdown","metadata":{},"source":["# 🔭 Prediction\n","对训练好的模型进行预测, 选了若干张没有标签的样本, 输入到模型中, 再和输出的掩码重叠一起打印"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:11:13.868637Z","iopub.status.busy":"2023-10-15T14:11:13.868181Z","iopub.status.idle":"2023-10-15T14:11:16.185694Z","shell.execute_reply":"2023-10-15T14:11:16.184774Z","shell.execute_reply.started":"2023-10-15T14:11:13.868601Z"},"trusted":true},"outputs":[],"source":["# def Predict (model, imgs, msks, size, plot_img = True) :\n","#     '''\n","#         输入模型, tensor 类型的图像, 标签, 即个数,\n","#         输出三行(或两行)图像, \n","#         第一行只有图像, \n","#         第二行为图像和标签的重叠,\n","#         第三行为图像和预测标签的重叠\n","#     '''\n","#     imgs = imgs.to (CFG.device, dtype = torch.float)\n","#     msks = msks.cpu ().detach () if not msks == None else None\n","#     with torch.no_grad () :\n","#         preds = model (imgs)\n","#         # 事实上这一步仅仅是用来把所有大于 0 的元素都置 1 了\n","#         # 因为类别仅有三种, 刚好可以分别用三个通道单独表示, 标签也是这么做的\n","#         # preds = (nn.Sigmoid ()(preds) > 0.5).double ().cpu ().detach ()\n","#         preds = (nn.Sigmoid ()(preds)).double ().cpu ().detach ()\n","#         for idx, pred in enumerate (preds) :\n","#             pred = pred.permute (1, 2, 0)\n","#             label = torch.argmax (pred, dim = 2)\n","#             pred = (pred > 0.5)\n","#             npred = F.one_hot (label, CFG.num_classes)\n","#             pred = pred * npred\n","#             pred = pred.permute (2, 0, 1)\n","#             preds[idx] = pred\n","#     imgs = imgs.cpu ().detach ()\n","#     if not plot_img : return preds\n","#     plot_batch (imgs, torch.zeros_like (imgs).cpu (), size = size)\n","#     if not msks == None : plot_batch (imgs, msks, size = size)\n","#     plot_batch (imgs, preds, size = size)\n","\n","# def GetPartImageAndMask (img, msk, lef_top = (32, 96), rig_bot = (128, 192)) :\n","#     '''\n","#         截取一对样本、标签的一个矩形区域\n","#         输入 3D tensor, shape = (通道数, 长, 宽)\n","#         lef_tor, tuple, 左上角坐标\n","#         rig_bot, typle, 右下角坐标\n","#     '''\n","#     x0, y0 = lef_top\n","#     x1, y1 = rig_bot\n","#     img = img[: , x0 : x1, y0 : y1]\n","#     msk = msk[: , x0 : x1, y0 : y1]\n","#     lef_pad = rig_pad = (CFG.img_size[1] - (y1 - y0)) // 2\n","#     top_pad = bot_pad = (CFG.img_size[0] - (x1 - x0)) // 2\n","#     pad = (lef_pad, rig_pad, top_pad, bot_pad)\n","#     img = F.pad (img, pad, mode = \"constant\", value = 0)\n","#     msk = F.pad (msk, pad, mode = \"constant\", value = 0)\n","#     return img, msk\n","\n","# def RandomSave (fold = 0, save_num = 5) :\n","#     '''\n","#         从数据集里随机找 save_num 个图像和标签, 保存在 output 里\n","#     '''\n","#     df_notEmpty = df.query(\"fold==@fold & empty==0\").reset_index (drop = True)\n","#     dataset = BuildDataset (df_notEmpty, transforms = data_transforms['valid'])\n","#     for i in range (save_num) :\n","#         img_PATH_new = f\"slice_{i}.png\"\n","#         msk_PATH_new = f\"slice_{i}.npy\"\n","#         id = random.randint (0, dataset.__len__ ())\n","#         img_PATH_old = dataset.img_paths[id]\n","#         msk_PATH_old = dataset.msk_paths[id]\n","# #         print (img_PATH_new, img_PATH_old)\n","#         shutil.copy (img_PATH_old, img_PATH_new)\n","#         shutil.copy (msk_PATH_old, msk_PATH_new)\n","        \n","# # test_fold = 0\n","# # model = load_model (\"resnet50\", f\"best_epoch-{test_fold:02d}.bin\")\n","# model = load_model (\"resnet50\", \"/kaggle/input/models-for-unet/model_unet_resnet50_2.bin\")  "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:11:16.187943Z","iopub.status.busy":"2023-10-15T14:11:16.187468Z","iopub.status.idle":"2023-10-15T14:11:24.795826Z","shell.execute_reply":"2023-10-15T14:11:24.795183Z","shell.execute_reply.started":"2023-10-15T14:11:16.187900Z"},"trusted":true},"outputs":[],"source":["# def PredictWithLabel (fold, model, df) :\n","#     '''\n","#         使用有标签的图像进行测试\n","#     '''\n","#     # 选择第一折的有标签的数据作为测试集, 不进行数据增强\n","#     test_dataset = BuildDataset (df.query (\"fold==@fold & empty==0\").sample (frac = 1.0), label = True, \n","#                             transforms = data_transforms['valid'])\n","#     test_loader  = DataLoader (test_dataset, batch_size = 5, \n","#                             num_workers = 4, shuffle = False, pin_memory = True)\n","#     # 获取一个批次大小 (5个) 的测试集\n","#     imgs, msks = next (iter (test_loader))\n","#     Predict (model, imgs, msks, 5)\n","\n","# PredictWithLabel (0, model, df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:11:24.798042Z","iopub.status.busy":"2023-10-15T14:11:24.797637Z","iopub.status.idle":"2023-10-15T14:11:27.173042Z","shell.execute_reply":"2023-10-15T14:11:27.172332Z","shell.execute_reply.started":"2023-10-15T14:11:24.797991Z"},"trusted":true},"outputs":[],"source":["# def PredictWithNoLabel (model, df) :\n","#     '''\n","#         使用无标签的图像进行测试\n","#     '''\n","#     test_dataset = BuildDataset (df.query (\"empty!=0\").sample (frac = 1.0), label = False, \n","#                             transforms = data_transforms['valid'])\n","#     test_loader  = DataLoader (test_dataset, batch_size = 5, \n","#                             num_workers = 4, shuffle = False, pin_memory = True)\n","#     imgs = next (iter (test_loader)).to (CFG.device, dtype = torch.float)\n","#     Predict (model, imgs, None, 5)\n","\n","# PredictWithNoLabel (model, df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:11:27.175239Z","iopub.status.busy":"2023-10-15T14:11:27.174789Z","iopub.status.idle":"2023-10-15T14:11:29.662739Z","shell.execute_reply":"2023-10-15T14:11:29.662042Z","shell.execute_reply.started":"2023-10-15T14:11:27.175205Z"},"trusted":true},"outputs":[],"source":["# def PredictWithPart (model, size = 5) :\n","#     '''\n","#         随机截取若干张图像的局部图像, 并进行预测\n","#     '''\n","#     RandomSave (save_num = size)\n","#     imgs, msks = [], []\n","#     for i in range (size) :\n","#         img_PATH = f\"/kaggle/working/slice_{i}.png\"\n","#         msk_PATH = f\"/kaggle/working/slice_{i}.npy\"\n","#         img, msk = png2tensor (img_PATH, msk_PATH)\n","#         img, msk = GetPartImageAndMask (img, msk)\n","#         imgs.append (img); msks.append (msk)\n","#     imgs = torch.stack (imgs, dim = 0)\n","#     msks = torch.stack (msks, dim = 0)\n","#     Predict (model, imgs, msks, size)\n","    \n","# PredictWithPart (model)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":false,"execution":{"iopub.execute_input":"2023-10-15T14:11:29.664450Z","iopub.status.busy":"2023-10-15T14:11:29.664077Z","iopub.status.idle":"2023-10-15T14:11:29.735252Z","shell.execute_reply":"2023-10-15T14:11:29.734493Z","shell.execute_reply.started":"2023-10-15T14:11:29.664416Z"},"trusted":true},"outputs":[],"source":["# def PredictionCompare (img, msk, models, save_path = None, pred_medsam = None) :\n","#     '''\n","#         输入图像和标签均为 tensor 类型\n","#         对比朴素 unet、resnet50_unet、medsam 三种模型的语义分割效果\n","#     '''\n","#     figure_cnt = len (models) + 2\n","#     plt.rcParams['figure.figsize'] = (5 * figure_cnt, 6)\n","# #     titles = [\"image\", \"mask\", \"unet\", \" unet-resnet50\", \"medsam\"]\n","# #     imgs = [img, msk, pred_unet, pred_unet_resnet50, pred_medsam]\n","#     preds, titles = [], ['image', 'mask']\n","#     img = img.unsqueeze (0)\n","#     msk = msk.unsqueeze (0)\n","#     for title, model in models.items () :\n","#         preds.append (Predict (model, img, msk, 1, plot_img = False).squeeze ())\n","#         titles.append (title)\n","#     img = img.squeeze ()\n","#     msk = msk.squeeze ()\n","#     imgs = [img, msk] + preds\n","#     if not pred_medsam == None :\n","#         imgs.append (pred_medsam)\n","#         titles.append (\"medsam\")\n","# #     for idx, image in e\n","# #         imgs[idx] = imgs[idx,].permute ((1, 2, 0)).numpy () * 255.\n","# #     imgs[0] = imgs[0].astype ('uint8')\n","    \n","#     for i, image in enumerate (imgs) :\n","#         image = image.permute ((1, 2, 0)).numpy () * 255.0\n","#         if i == 0 : image = image.astype ('uint8')\n","#         imgs[i] = image\n","#         plt.subplot (1, figure_cnt, i + 1)\n","#         plt.title (titles[i], fontsize = \"32\")\n","#         if i == 0 : show_img (img = imgs[0], mask = None)\n","#         else : show_img (img = imgs[0], mask = image)\n","#     plt.tight_layout ()\n","#     if not save_path == None : plt.savefig (save_PATH); print (save_PATH)\n","#     plt.show ()"]},{"cell_type":"markdown","metadata":{},"source":["# 📃 Save Files\n","通过上述训练过程，得到了若干种使用不同编码器的 $Unet$ 模型，枚举他们的子集，并选取十张图片进行测试结果对比，保存测试结果图片，并通过 $wandb$ 将测试结果图片打包成压缩包后上传到云端。"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":false,"execution":{"iopub.execute_input":"2023-10-15T14:15:29.466604Z","iopub.status.busy":"2023-10-15T14:15:29.466089Z","iopub.status.idle":"2023-10-15T14:15:36.747853Z","shell.execute_reply":"2023-10-15T14:15:36.747046Z","shell.execute_reply.started":"2023-10-15T14:15:29.466566Z"},"trusted":true},"outputs":[],"source":["model_unet_densenet161 = load_model (\"densenet161\", \"models-for-unet/model_unet_densenet161.bin\")\n","model_unet_efficientnet_b4 = load_model (\"efficientnet-b4\", \"models-for-unet/model_unet_efficientnet_b4.bin\")\n","model_unet_efficientnet_b5 = load_model (\"efficientnet-b5\", \"models-for-unet/model_unet_efficientnet_b5.bin\")\n","model_unet_mit_b2 = load_model (\"mit_b2\", \"models-for-unet/model_unet_mit_b2.bin\")\n","model_unet_mobilenet_v2 = load_model (\"mobilenet_v2\", \"models-for-unet/model_unet_mobilenet_v2.bin\")\n","model_unet_resnet101 = load_model (\"resnet101\", \"models-for-unet/model_unet_resnet101.bin\")\n","model_unet_resnet50 = load_model (\"resnet50\", \"models-for-unet/model_unet_resnet50_2.bin\")\n","model_unet_se_resnet50 = load_model (\"se_resnet50\", \"models-for-unet/model_unet_se_resnet50.bin\")\n","models = {\n","        #   \"densenet161\"     : model_unet_densenet161,\n","        #   \"efficientnet-b4\" : model_unet_efficientnet_b4,\n","        #   \"efficientnet-b5\" : model_unet_efficientnet_b5, \n","          \"mit-b2\"          : model_unet_mit_b2,\n","        #   \"mobilenet-v2\"    : model_unet_mobilenet_v2,\n","        #   \"resnet101\"       : model_unet_resnet101,\n","        #   \"resnet50\"        : model_unet_resnet50,\n","        #   \"se-resnet50\"     : model_unet_se_resnet50}\n","}\n","\n","def bindigits(n, bits):\n","    s = bin(n & int(\"1\"*bits, 2))[2:]\n","    return (\"{0:0>%s}\" % (bits)).format(s)\n","\n","# 取所有模型的集合的一个子集, 对同一张图片进行预测结果的可视化对比, 对比十次\n","# %mkdir -p \"figures\"\n","# model_cnt = len (models)\n","# key_value = list (models.items ())\n","# RandomSave (fold = random.randint (0, 4), save_num = 10)\n","# for i in range (1, 1 << model_cnt) :\n","#     dir_PATH = \"figures/\" + str (bindigits (i, model_cnt))\n","#     sub_models = dict ()\n","#     base_PATH = str (\"/kaggle/working/\") + str (dir_PATH) + str (\"/\")\n","#     cnt = 0\n","#     for j in range (model_cnt) :\n","#         if (i >> j) & 1 : \n","#             sub_models[key_value[j][0]] = key_value[j][1]\n","#             if cnt > 0 : base_PATH += \"|\"\n","#             cnt += 1\n","#             base_PATH += str (key_value[j][0])\n","#     if cnt < 4 : continue\n","#     isExists = os.path.exists (dir_PATH)\n","#     if not isExists:\n","#         os.makedirs (dir_PATH)\n","#         print(\"%s 目录创建成功\" % dir_PATH)\n","#     else:\n","#         print(\"目录已经存在\")\n","#     for k in range (10) :\n","#         img_PATH = f\"/kaggle/working/slice_{k}.png\"\n","#         msk_PATH = f\"/kaggle/working/slice_{k}.npy\"\n","#         img, msk = png2tensor (img_PATH, msk_PATH)\n","#         img, msk = GetPartImageAndMask (img, msk)\n","#         save_PATH = base_PATH + f\"|{k:02d}.png\"\n","#         PredictionCompare (img, msk, sub_models, save_PATH)\n","#     gc.collect ()"]},{"cell_type":"markdown","metadata":{},"source":["打包成压缩包并上传到 $wandb$。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:11:40.531678Z","iopub.status.busy":"2023-10-15T14:11:40.531439Z","iopub.status.idle":"2023-10-15T14:11:40.595790Z","shell.execute_reply":"2023-10-15T14:11:40.595058Z","shell.execute_reply.started":"2023-10-15T14:11:40.531641Z"},"trusted":true},"outputs":[],"source":["# import zipfile, os\n","\n","\n","# def zipDir (dirpath, outFullName) :\n","#     \"\"\"\n","#     压缩指定文件夹\n","#     :param dirpath: 目标文件夹路径\n","#     :param outFullName: 压缩文件保存路径+xxxx.zip\n","#     :return: 无\n","#     \"\"\"\n","#     zip = zipfile.ZipFile (outFullName, \"w\", zipfile.ZIP_DEFLATED)\n","#     for path, dirnames, filenames in os.walk (dirpath):\n","#         # 去掉目标跟路径，只对目标文件夹下边的文件及文件夹进行压缩\n","#         fpath = path.replace (dirpath, '')\n"," \n","#         for filename in filenames:\n","#             zip.write (os.path.join (path, filename), os.path.join (fpath, filename))\n","#     zip.close ()\n","\n","# zip_PATH = \"/kaggle/working/figures\"\n","# out_PATH = \"/kaggle/working/results.zip\"\n","# zipDir (zip_PATH, out_PATH)\n","# run = wandb.init (project ='Unet-For-UWMGI-Analysis', \n","#                  anonymous = anonymous,\n","#                  name = \"Comparison for complete scans between all models\"\n","#                 )\n","# wandb.save (\"/kaggle/working/results.zip\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:11:40.597408Z","iopub.status.busy":"2023-10-15T14:11:40.596978Z","iopub.status.idle":"2023-10-15T14:11:40.660226Z","shell.execute_reply":"2023-10-15T14:11:40.659449Z","shell.execute_reply.started":"2023-10-15T14:11:40.597362Z"},"trusted":true},"outputs":[],"source":["# images  = images.to (device, dtype = torch.float)\n","# masks   = masks.to (device, dtype = torch.float)\n","\n","# batch_size = images.size (0)\n","\n","# y_pred  = model (images)\n","# loss    = criterion (y_pred, masks)\n","\n","# running_loss += (loss.item () * batch_size)\n","# dataset_size += batch_size\n","\n","# epoch_loss = running_loss / dataset_size\n","\n","# y_pred = nn.Sigmoid () (y_pred)\n","# val_dice = dice_coef (masks, y_pred).cpu ().detach ().numpy ()\n","# val_jaccard = iou_coef (masks, y_pred).cpu ().detach ().numpy ()\n","# val_scores.append ([val_dice, val_jaccard])\n","    \n","# RandomSave (fold = random.randint (0, 4), save_num = 1000)\n","# for name, test_model in models.items () :\n","#     val_dice, val_jaccard = 0, 0\n","#     for k in tqdm (range (1000), total = 1000) :\n","#         img_PATH     = f\"/kaggle/working/slice_{k}.png\"\n","#         msk_PATH     = f\"/kaggle/working/slice_{k}.npy\"\n","#         img, msk     = png2tensor (img_PATH, msk_PATH)\n","#         img, msk     = GetPartImageAndMask (img, msk)\n","#         images       = img.unsqueeze (0).to (CFG.device, dtype = torch.float)\n","#         masks        = msk.unsqueeze (0).to (CFG.device, dtype = torch.float)\n","#         y_pred       = test_model (images)\n","#         y_pred       = nn.Sigmoid () (y_pred)\n","#         val_dice    += dice_coef (masks, y_pred).cpu ().detach ().numpy ()\n","#         val_jaccard += iou_coef (masks, y_pred).cpu ().detach ().numpy ()\n","#     val_dice /= 1000.0; val_jaccard /= 1000.0\n","#     print (name, f\"dice :{val_dice}\", f\"iou : {val_jaccard}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:15:36.749901Z","iopub.status.busy":"2023-10-15T14:15:36.749491Z","iopub.status.idle":"2023-10-15T14:15:37.166026Z","shell.execute_reply":"2023-10-15T14:15:37.164821Z","shell.execute_reply.started":"2023-10-15T14:15:36.749864Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model_summary_mit-b2.txt\n"]},{"ename":"ValueError","evalue":"setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\Users\\pc\\Desktop\\Charming\\AI\\Unet-For-UWMGI\\unet-for-uwmgi.ipynb 单元格 55\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/Desktop/Charming/AI/Unet-For-UWMGI/unet-for-uwmgi.ipynb#Y105sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m (output_file)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/Desktop/Charming/AI/Unet-For-UWMGI/unet-for-uwmgi.ipynb#Y105sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mwith\u001b[39;00m stdout_redirected (to \u001b[39m=\u001b[39m output_file) :\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pc/Desktop/Charming/AI/Unet-For-UWMGI/unet-for-uwmgi.ipynb#Y105sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     summary (test_model, input_size \u001b[39m=\u001b[39;49m (\u001b[39m3\u001b[39;49m, \u001b[39m224\u001b[39;49m, \u001b[39m224\u001b[39;49m), batch_size \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, device \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n","File \u001b[1;32mc:\\Software\\miniconda3\\lib\\site-packages\\torchsummary\\torchsummary.py:99\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     93\u001b[0m line_new \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{:>20}\u001b[39;00m\u001b[39m  \u001b[39m\u001b[39m{:>25}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{:>15}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     94\u001b[0m     layer,\n\u001b[0;32m     95\u001b[0m     \u001b[39mstr\u001b[39m(summary[layer][\u001b[39m\"\u001b[39m\u001b[39moutput_shape\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[0;32m     96\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{0:,}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(summary[layer][\u001b[39m\"\u001b[39m\u001b[39mnb_params\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[0;32m     97\u001b[0m )\n\u001b[0;32m     98\u001b[0m total_params \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m summary[layer][\u001b[39m\"\u001b[39m\u001b[39mnb_params\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m---> 99\u001b[0m total_output \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mprod(summary[layer][\u001b[39m\"\u001b[39;49m\u001b[39moutput_shape\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtrainable\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m summary[layer]:\n\u001b[0;32m    101\u001b[0m     \u001b[39mif\u001b[39;00m summary[layer][\u001b[39m\"\u001b[39m\u001b[39mtrainable\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n","File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n","File \u001b[1;32mc:\\Software\\miniconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3076\u001b[0m, in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2955\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_prod_dispatcher)\n\u001b[0;32m   2956\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprod\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[0;32m   2957\u001b[0m          initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[0;32m   2958\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2959\u001b[0m \u001b[39m    Return the product of array elements over a given axis.\u001b[39;00m\n\u001b[0;32m   2960\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[39m    10\u001b[39;00m\n\u001b[0;32m   3075\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3076\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmultiply, \u001b[39m'\u001b[39;49m\u001b[39mprod\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out,\n\u001b[0;32m   3077\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n","File \u001b[1;32mc:\\Software\\miniconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n","\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."]}],"source":["import sys\n","from torchsummary import summary\n","from contextlib import contextmanager\n"," \n","@contextmanager\n","def stdout_redirected (to = None) :\n","    \"\"\"\n","    上下文管理器, 用于临时将stdout重定向到文件或控制台。\n","    使用方法：`with stdout_redirected to='output.txt'):`\n","    \"\"\"\n","    if to is None:\n","        yield\n","    else:\n","        sys.stdout.flush ()\n","        original_stdout = sys.stdout\n","        with open (to, 'w') as file:\n","            sys.stdout = file\n","            try:\n","                yield file\n","            finally :\n","                sys.stdout = original_stdout\n","\n","with torch.no_grad () :\n","    for name, test_model in models.items () :\n","        output_file = \"model_summary_\" + name + \".txt\"\n","        print (output_file)\n","        with stdout_redirected (to = output_file) :\n","            summary (test_model, input_size = (3, 224, 224), batch_size = 1, device = \"cpu\")"]},{"cell_type":"markdown","metadata":{},"source":["# ✂️ Remove Files"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T14:11:41.218563Z","iopub.status.busy":"2023-10-15T14:11:41.218054Z","iopub.status.idle":"2023-10-15T14:11:42.379566Z","shell.execute_reply":"2023-10-15T14:11:42.378665Z","shell.execute_reply.started":"2023-10-15T14:11:41.218523Z"},"trusted":true},"outputs":[],"source":["# !rm -r ./wandb"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"}},"nbformat":4,"nbformat_minor":4}
